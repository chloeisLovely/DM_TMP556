# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬

import streamlit as st
import pandas as pd
import numpy as np
import io 
import os

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
try:
    from xgboost import XGBClassifier
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False
    
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix,
    classification_report, RocCurveDisplay
)

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid", font_scale=1.1)


# 1. ê³µí†µ í•¨ìˆ˜

def get_metrics(model, X_ev, y_ev):
    """ëª¨ë¸ê³¼ í‰ê°€ ë°ì´í„°ë¥¼ ë°›ì•„ ì§€í‘œ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜"""
    try:
        proba = model.predict_proba(X_ev)[:, 1]
        pred = (proba >= 0.5).astype(int)
        return {
            "accuracy": accuracy_score(y_ev, pred),
            "precision": precision_score(y_ev, pred, zero_division=0),
            "recall": recall_score(y_ev, pred, zero_division=0),
            "f1": f1_score(y_ev, pred, zero_division=0),
            "roc_auc": roc_auc_score(y_ev, proba),
        }
    except Exception as e:
        st.error(f"ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def plot_confusion(y_true, y_pred, cmap="Blues"):
    """Confusion Matrix ì°¨íŠ¸ ìƒì„±"""
    cm = confusion_matrix(y_true, y_pred)
    fig = plt.figure(figsize=(4, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap=cmap)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.tight_layout()
    return fig

def plot_roc_curve(y_true, proba, name):
    """ROC Curve ì°¨íŠ¸ ìƒì„±"""
    fig = plt.figure(figsize=(6, 5))
    ax = fig.add_subplot(111)
    RocCurveDisplay.from_predictions(y_true, proba, name=name, ax=ax)
    ax.plot([0, 1], [0, 1], "k--", alpha=0.3)
    ax.set_title("ROC Curve")
    plt.tight_layout()
    return fig

@st.cache_data
def convert_fig_to_png(_fig): # 1. fig -> _fig ë¡œ ë³€ê²½ (ìºì‹œ ì˜¤ë¥˜ ìˆ˜ì •)
    """Matplotlib Figureë¥¼ PNG ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¡œ ë³€í™˜ (ìºì‹œ í•´ì‹œ ë¹„í™œì„±í™”)"""
    buf = io.BytesIO()
    _fig.savefig(buf, format="png", bbox_inches='tight') # 2. ë‚´ë¶€ ë³€ìˆ˜ë„ _fig ë¡œ ë³€ê²½
    buf.seek(0)
    return buf.getvalue()

@st.cache_data
def convert_df_to_csv(df):
    """DataFrameì„ CSV ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
    return df.to_csv(index=True).encode('utf-8')


# 2. ë°ì´í„° ë¶„í•  ë° ëª¨ë¸ í›ˆë ¨ í•¨ìˆ˜ (ìºì‹œ ì—†ìŒ)

def split_data(X, y, test_ratio, val_ratio):
    """ì‚¬ìš©ì ì„¤ì • ë¹„ìœ¨ì— ë”°ë¼ Train/Val/Testë¡œ ë¶„í• """
    # 1ë‹¨ê³„: Test ë¶„ë¦¬
    X_train_val, X_test, y_train_val, y_test = train_test_split(
        X, y, 
        test_size=test_ratio, 
        stratify=y, 
        random_state=42
    )
    
    # 2ë‹¨ê³„: ë‚¨ì€ ë°ì´í„°(Train+Val)ì—ì„œ Val ë¶„ë¦¬
    # (Train+Val) í¬ê¸° ëŒ€ë¹„ Val í¬ê¸° ë¹„ìœ¨ ê³„ì‚°
    if (1.0 - test_ratio) == 0: # test_ratioê°€ 1.0ì¼ ê²½ìš° ë°©ì§€
        val_ratio_within = 0
    else:
        val_ratio_within = val_ratio / (1.0 - test_ratio)
    
    # val_ratio_withinì´ 1.0 ì´ìƒì´ë©´ Valì´ Train+Valë³´ë‹¤ í¬ê²Œ ì„¤ì •ëœ ê²ƒì´ë¯€ë¡œ ì¡°ì •
    if val_ratio_within >= 1.0:
        val_ratio_within = 0.99 # ê±°ì˜ ëª¨ë“  ê²ƒì„ Valë¡œ (ë¹„ì •ìƒì ì´ì§€ë§Œ ì—ëŸ¬ ë°©ì§€)

    X_train, X_val, y_train, y_val = train_test_split(
        X_train_val, y_train_val,
        test_size=val_ratio_within,
        stratify=y_train_val,
        random_state=42
    )
    return X_train, X_val, X_test, y_train, y_val, y_test

def train_models(X_train, y_train, numeric_features, categorical_features):
    """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í¬í•¨í•œ 4ê°œ ëª¨ë¸ì„ í›ˆë ¨"""
    
    # transformers ë¦¬ìŠ¤íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. (ValueError ìˆ˜ì •)
    transformers_list = []

    if numeric_features: # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ë•Œë§Œ ì¶”ê°€
        transformers_list.append(
            ("num", StandardScaler(), numeric_features)
        )
    
    if categorical_features: # ë²”ì£¼í˜• ë³€ìˆ˜ê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ë•Œë§Œ ì¶”ê°€
        transformers_list.append(
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
        )

    if not transformers_list:
        st.warning("ë¶„ì„í•  ìˆ˜ì¹˜í˜• ë˜ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    preprocess = ColumnTransformer(
        transformers=transformers_list, # ë™ì ìœ¼ë¡œ ìƒì„±ëœ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        remainder="passthrough" # ì„ íƒë˜ì§€ ì•Šì€ í”¼ì²˜ëŠ” í†µê³¼ì‹œí‚´
    )

    # 5-fold êµì°¨ ê²€ì¦ ì„¤ì •
    cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    models_dict = {}
    
    with st.spinner("1/4: Logistic Regression í›ˆë ¨ ì¤‘..."):
        log_pipeline = Pipeline(steps=[
            ("preprocess", preprocess),
            ("clf", LogisticRegression(max_iter=1000, class_weight="balanced", solver="liblinear"))
        ])
        log_param_grid = {"clf__C": [0.1, 1.0, 10.0]} # ì†ë„ë¥¼ ìœ„í•´ íŒŒë¼ë¯¸í„° ì¶•ì†Œ
        log_cv = GridSearchCV(log_pipeline, log_param_grid, scoring="roc_auc", cv=cv_stratified, n_jobs=-1, refit=True)
        log_cv.fit(X_train, y_train)
        models_dict["Logistic"] = log_cv.best_estimator_

    with st.spinner("2/4: Decision Tree í›ˆë ¨ ì¤‘..."):
        dt_pipeline = Pipeline(steps=[
            ("preprocess", preprocess),
            ("clf", DecisionTreeClassifier(class_weight="balanced", random_state=42))
        ])
        dt_param_grid = {"clf__max_depth": [5, 10, None], "clf__min_samples_split": [2, 10]}
        dt_cv = GridSearchCV(dt_pipeline, dt_param_grid, scoring="roc_auc", cv=cv_stratified, n_jobs=-1, refit=True)
        dt_cv.fit(X_train, y_train)
        models_dict["Decision Tree"] = dt_cv.best_estimator_

    with st.spinner("3/4: Random Forest í›ˆë ¨ ì¤‘..."):
        rf_pipeline = Pipeline(steps=[
            ("preprocess", preprocess),
            ("clf", RandomForestClassifier(class_weight="balanced", random_state=42))
        ])
        rf_param_grid = {"clf__n_estimators": [100, 200], "clf__max_depth": [10, None]}
        rf_cv = GridSearchCV(rf_pipeline, rf_param_grid, scoring="roc_auc", cv=cv_stratified, n_jobs=-1, refit=True)
        rf_cv.fit(X_train, y_train)
        models_dict["Random Forest"] = rf_cv.best_estimator_

    if XGB_AVAILABLE:
        with st.spinner("4/4: XGBoost í›ˆë ¨ ì¤‘..."):
            # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨ ê³„ì‚°
            pos = y_train.sum()
            neg = (y_train == 0).sum()
            scale_pos_weight = neg / pos if pos > 0 else 1 # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€
            
            xgb_pipeline = Pipeline(steps=[
                ("preprocess", preprocess),
                ("clf", XGBClassifier(random_state=42, n_jobs=-1, eval_metric="logloss", scale_pos_weight=scale_pos_weight))
            ])
            xgb_param_grid = {"clf__n_estimators": [100, 200], "clf__max_depth": [3, 5]}
            xgb_cv = GridSearchCV(xgb_pipeline, xgb_param_grid, scoring="roc_auc", cv=cv_stratified, n_jobs=-1, refit=True)
            xgb_cv.fit(X_train, y_train)
            models_dict["XGBoost"] = xgb_cv.best_estimator_
    else:
        st.warning("XGBoost ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. XGBoost ëª¨ë¸ì„ ì œì™¸í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")
    
    return models_dict


# 3. Streamlit ì•± ë©”ì¸ í•¨ìˆ˜

def main():
    st.set_page_config(page_title="ë²”ìš© ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ ëŒ€ì‹œë³´ë“œ", layout="wide")
    st.title("ğŸ‘ ë²”ìš© ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ ëŒ€ì‹œë³´ë“œ")
    st.markdown("ì–´ë–¤ CSV íŒŒì¼ì´ë“  ì—…ë¡œë“œí•˜ì—¬ 4ê°€ì§€ ì£¼ìš” ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµ, í‰ê°€, ì‹œê°í™”í•©ë‹ˆë‹¤.")

    # --- Session State ì´ˆê¸°í™” ---
    # (ì•± ì¬ì‹¤í–‰ ì‹œ ìœ ì§€ë˜ì–´ì•¼ í•  ê°’ë“¤)
    if 'analysis_run' not in st.session_state:
        st.session_state.analysis_run = False # ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€
    if 'metrics_df' not in st.session_state:
        st.session_state.metrics_df = None # í‰ê°€ ê²°ê³¼
    if 'models_dict' not in st.session_state:
        st.session_state.models_dict = None # í›ˆë ¨ëœ ëª¨ë¸
    if 'label_encoder' not in st.session_state:
        st.session_state.label_encoder = None # íƒ€ê¹ƒ ì¸ì½”ë”
    if 'test_data' not in st.session_state:
        st.session_state.test_data = (None, None) # (X_test, y_test)
    if 'final_metric' not in st.session_state:
        st.session_state.final_metric = 'recall' # ìµœì¢… ì„ íƒ ì§€í‘œ
    if 'sample_loaded' not in st.session_state:
        st.session_state.sample_loaded = False
    if 'current_file' not in st.session_state:
        st.session_state.current_file = None


    # --- ì‚¬ì´ë“œë°” ì„¤ì • ---
    st.sidebar.header("âš™ï¸ 1. ë¶„ì„ ì„¤ì •")
    uploaded_file = st.sidebar.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

    if uploaded_file is None:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        st.markdown("")
        # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© ì˜µì…˜ (cleaned_hr_attrition_dataset.csvê°€ ìˆë‹¤ê³  ê°€ì •)
        if os.path.exists("cleaned_hr_attrition_dataset.csv"):
            st.sidebar.markdown("---")
            if st.sidebar.button("ìƒ˜í”Œ HR ë°ì´í„°ë¡œ ë¶„ì„í•˜ê¸°"):
                uploaded_file = "cleaned_hr_attrition_dataset.csv"
                st.session_state.sample_loaded = True # ìƒ˜í”Œ ë¡œë“œ ìƒíƒœ ì €ì¥
                st.session_state.analysis_run = False # ìƒ˜í”Œ ë¡œë“œì‹œ ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
                st.rerun() # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        else:
             st.sidebar.caption("'cleaned_hr_attrition_dataset.csv' íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë‘ë©´ ìƒ˜í”Œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")
    
    # (ì„¸ì…˜ ìƒíƒœë¥¼ ì´ìš©í•´ ìƒ˜í”Œ ë¡œë“œ ìœ ì§€)
    if not uploaded_file and st.session_state.sample_loaded:
         uploaded_file = "cleaned_hr_attrition_dataset.csv"

    if uploaded_file is not None:
        try:
            # íŒŒì¼ì´ ë³€ê²½ë˜ë©´ ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
            file_name = uploaded_file.name if hasattr(uploaded_file, 'name') else uploaded_file
            if st.session_state.current_file != file_name:
                st.session_state.analysis_run = False
                st.session_state.current_file = file_name

            df = pd.read_csv(uploaded_file)
            st.sidebar.success(f"'{file_name}' ë¡œë“œ ì„±ê³µ!")
            
            with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)"):
                st.dataframe(df.head())

            # --- 2. ë³€ìˆ˜ ì„¤ì • ---
            st.sidebar.header("ğŸ¯ 2. ë³€ìˆ˜ ì„¤ì •")
            all_columns = df.columns.tolist()
            
            # (ìƒ˜í”Œ ë°ì´í„°ì˜ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •)
            default_target_idx = 0
            if "AttritionFlag" in all_columns:
                default_target_idx = all_columns.index("AttritionFlag")
            elif len(all_columns) > 0:
                default_target_idx = len(all_columns) - 1 # ë§ˆì§€ë§‰ ì»¬ëŸ¼
                
            target_variable = st.sidebar.selectbox(
                "íƒ€ê¹ƒ(Y) ë³€ìˆ˜ ì„ íƒ (í•„ìˆ˜, 2ê°œ ê°’)",
                all_columns,
                index=default_target_idx
            )
            
            feature_candidates = [col for col in all_columns if col != target_variable]
            excluded_features = st.sidebar.multiselect(
                "ë¶„ì„ì—ì„œ ì œì™¸í•  ë³€ìˆ˜ ì„ íƒ",
                feature_candidates,
                default=[]
            )
            selected_features = [col for col in feature_candidates if col not in excluded_features]

            # --- 3. ë°ì´í„° ë¶„í•  ì„¤ì • ---
            st.sidebar.header("âœ‚ï¸ 3. ë°ì´í„° ë¶„í•  ë¹„ìœ¨")
            test_ratio = st.sidebar.slider("í…ŒìŠ¤íŠ¸(Test) ì„¸íŠ¸ ë¹„ìœ¨", 0.1, 0.5, 0.15, 0.05)
            val_ratio = st.sidebar.slider("ê²€ì¦(Validation) ì„¸íŠ¸ ë¹„ìœ¨", 0.1, 0.5, 0.25, 0.05)
            
            train_ratio = 1.0 - test_ratio - val_ratio
            
            if train_ratio <= 0.1: # í›ˆë ¨ì…‹ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ê²½ê³ 
                st.sidebar.error(f"í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨ì´ {train_ratio*100:.0f}%ë¡œ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸/ê²€ì¦ ë¹„ìœ¨ì„ ë‚®ì¶°ì£¼ì„¸ìš”.")
                st.stop()
            else:
                st.sidebar.info(f"í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨: **{train_ratio*100:.0f}%**")

            # --- 4. ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ ---
            st.sidebar.markdown("---")
            if st.sidebar.button("ğŸš€ ëª¨ë¸ í›ˆë ¨ ë° ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                
                # --- [ì‹œì‘] ë¶„ì„ íŒŒì´í”„ë¼ì¸ ---
                st.header("ğŸ”¬ 1. ë¶„ì„ ì¤€ë¹„")
                
                y = df[target_variable]
                if y.nunique() != 2:
                    st.error(f"ì˜¤ë¥˜: íƒ€ê¹ƒ ë³€ìˆ˜ '{target_variable}'ì˜ ê³ ìœ ê°’ì´ 2ê°œê°€ ì•„ë‹™ë‹ˆë‹¤ (í˜„ì¬: {y.nunique()}ê°œ). ì´ì§„ ë¶„ë¥˜ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                    st.stop()
                
                le = LabelEncoder()
                y_encoded = le.fit_transform(y)
                target_mapping = {label: idx for idx, label in enumerate(le.classes_)}
                st.info(f"íƒ€ê¹ƒ ë³€ìˆ˜ '{target_variable}' ì¸ì½”ë”©: {target_mapping}")

                X = df[selected_features]
                numeric_features = X.select_dtypes(include=np.number).columns.tolist()
                categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
                
                if not numeric_features and not categorical_features:
                    st.error("ì˜¤ë¥˜: ë¶„ì„í•  í”¼ì²˜(X) ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. 'ì œì™¸í•  ë³€ìˆ˜' ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()

                st.write(f"**ì´ {len(selected_features)}ê°œ í”¼ì²˜ ì‚¬ìš©:**")
                st.write(f"- ğŸ“ˆ **ìˆ˜ì¹˜í˜•({len(numeric_features)}ê°œ):** `{', '.join(numeric_features) if numeric_features else 'ì—†ìŒ'}`")
                st.write(f"- ğŸ”  **ë²”ì£¼í˜•({len(categorical_features)}ê°œ):** `{', '.join(categorical_features) if categorical_features else 'ì—†ìŒ'}`")

                X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y_encoded, test_ratio, val_ratio)
                st.write(f"**ë°ì´í„° ë¶„í•  ê²°ê³¼:** í›ˆë ¨ {len(y_train)}ê°œ, ê²€ì¦ {len(y_val)}ê°œ, í…ŒìŠ¤íŠ¸ {len(y_test)}ê°œ")
                
                st.header("ğŸƒ 2. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€")
                models_dict = train_models(X_train, y_train, numeric_features, categorical_features)

                rows = []
                for name, model in models_dict.items():
                    val_metrics = get_metrics(model, X_val, y_val)
                    test_metrics = get_metrics(model, X_test, y_test)
                    if val_metrics: rows.append({"model": name, "set": "Validation", **val_metrics})
                    if test_metrics: rows.append({"model": name, "set": "Test", **test_metrics})
                
                metrics_df = pd.DataFrame(rows).set_index(["model", "set"]).round(4)
                
                # --- Session Stateì— ê²°ê³¼ ì €ì¥ ---
                st.session_state.analysis_run = True
                st.session_state.metrics_df = metrics_df
                st.session_state.models_dict = models_dict
                st.session_state.label_encoder = le
                st.session_state.test_data = (X_test, y_test)
                st.rerun() # ë²„íŠ¼ í´ë¦­ í›„ ì¦‰ì‹œ ì¬ì‹¤í–‰í•˜ì—¬ ì•„ë˜ `if` ë¸”ë¡ì„ íƒ€ë„ë¡ í•¨

        except pd.errors.ParserError:
            st.error("ì˜¤ë¥˜: CSV íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ìœ íš¨í•œ CSV í˜•ì‹ì´ ì•„ë‹Œì§€ í™•ì¸í•˜ì„¸ìš”.")
            st.session_state.analysis_run = False
        except KeyError as e:
            st.error(f"ì˜¤ë¥˜: '{e}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë³€ìˆ˜ ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
            st.session_state.analysis_run = False
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤€ë¹„ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.session_state.analysis_run = False

    # --- ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë¡œì§ (Session State ê¸°ë°˜) ---
    if st.session_state.analysis_run:
        # Session Stateì—ì„œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
        metrics_df = st.session_state.metrics_df
        models_dict = st.session_state.models_dict
        le = st.session_state.label_encoder
        X_test, y_test = st.session_state.test_data

        if metrics_df is None or models_dict is None or le is None or X_test is None:
             st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ëª¨ë¸ í›ˆë ¨ ë° ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
             st.stop()
             
        # --- 1.5. ëª¨ë¸ í‰ê°€ (í‘œì‹œ) ---
        st.header("ğŸ“Š 2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµí‘œ")
        st.dataframe(metrics_df.style.highlight_max(axis=0, color="lightgreen"))
        st.download_button(
            label="ì„±ëŠ¥ ë¹„êµí‘œ (CSV) ë‹¤ìš´ë¡œë“œ",
            data=convert_df_to_csv(metrics_df),
            file_name="model_metrics.csv",
            mime="text/csv",
        )

        # --- 1.6. ì„±ëŠ¥ ì‹œê°í™” (í‘œì‹œ) ---
        st.header("ğŸ“ˆ 3. ì„±ëŠ¥ ì‹œê°í™” (Test Set ê¸°ì¤€)")
        test_metrics = metrics_df.xs("Test", level="set")
        
        col1, col2 = st.columns(2)
        
        # ROC-AUC ë¹„êµ
        fig_roc_comp = plt.figure(figsize=(7, 5))
        test_metrics["roc_auc"].sort_values().plot(kind="barh", ax=fig_roc_comp.add_subplot(111))
        plt.title("Test Set: ROC-AUC Comparison")
        plt.xlabel("ROC-AUC Score")
        col1.pyplot(fig_roc_comp)
        
        # Recall ë¹„êµ
        fig_recall_comp = plt.figure(figsize=(7, 5))
        test_metrics["recall"].sort_values().plot(kind="barh", ax=fig_recall_comp.add_subplot(111))
        plt.title("Test Set: Recall Comparison")
        plt.xlabel("Recall Score")
        col2.pyplot(fig_recall_comp)

        st.download_button(
            label="ROC-AUC ë¹„êµ ì°¨íŠ¸ (PNG) ë‹¤ìš´ë¡œë“œ",
            data=convert_fig_to_png(fig_roc_comp),
            file_name="roc_auc_comparison.png",
            mime="image/png",
        )

        # --- 1.7. ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„ (í‘œì‹œ) ---
        st.header("ğŸ” 4. ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„ (Test Set)")
        tab_names = list(models_dict.keys())
        tabs = st.tabs(tab_names)
        
        for i, name in enumerate(tab_names):
            with tabs[i]:
                model = models_dict[name]
                proba = model.predict_proba(X_test)[:, 1]
                pred = (proba >= 0.5).astype(int)
                
                st.subheader(f"{name}: ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°")
                st.json(model.named_steps['clf'].get_params())
                
                tcol1, tcol2 = st.columns([1, 2])
                
                fig_cm = plot_confusion(y_test, pred, cmap="Reds" if name == "Logistic" else "Blues")
                tcol1.pyplot(fig_cm)
                
                fig_roc_ind = plot_roc_curve(y_test, proba, name)
                tcol2.pyplot(fig_roc_ind)
                
                # --- [ìˆ˜ì •] Classification Reportë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ ---
                st.subheader("Classification Report")
                try:
                    # output_dict=Trueë¡œ ë”•ì…”ë„ˆë¦¬ ë°›ê¸°
                    report_dict = classification_report(y_test, pred, target_names=[str(c) for c in le.classes_], output_dict=True)
                    # DataFrameìœ¼ë¡œ ë³€í™˜
                    report_df = pd.DataFrame(report_dict).transpose().round(4)
                    # st.dataframeìœ¼ë¡œ ê¹”ë”í•˜ê²Œ í‘œì‹œ
                    st.dataframe(report_df)
                except Exception as e:
                    st.error(f"Report ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                    st.text(classification_report(y_test, pred, target_names=[str(c) for c in le.classes_])) # ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                # --- [ìˆ˜ì • ë] ---

        # --- 1.8. ìµœì¢… ê²°ë¡  (í‘œì‹œ) ---
        st.header("ğŸ’¡ 5. ìµœì¢… ê²°ë¡ ")
        st.subheader("ğŸ‘Œí•µì‹¬ ì§€í‘œì— ë”°ë¥¸ ìµœì  ëª¨ë¸")
        
        metric_to_optimize = st.selectbox(
            "ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì§€í‘œ(Metric)ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            ["recall", "roc_auc", "accuracy", "precision", "f1"],
            key='final_metric' # st.session_stateì™€ ì—°ë™
        )
        
        # test_metricsê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
        if not test_metrics.empty:
            best_model_name = test_metrics[st.session_state.final_metric].idxmax()
            best_score = test_metrics.loc[best_model_name, st.session_state.final_metric]
            
            st.success(f"**'{st.session_state.final_metric.upper()}'** ì§€í‘œ ê¸°ì¤€, ìµœì  ëª¨ë¸ì€ **'{best_model_name}'** (ì ìˆ˜: {best_score:.4f}) ì…ë‹ˆë‹¤.")
        else:
            st.warning("Test Set í‰ê°€ì§€í‘œë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # --- [ìˆ˜ì •] ì§€í‘œ ì„¤ëª…ì„ HR ì˜ˆì‹œë¡œ ë³€ê²½ ë° Accuracy ì¶”ê°€ ---
        st.markdown(
            """
            - **Accuracy (ì •í™•ë„)ê°€ ì¤‘ìš”í•˜ë‹¤ë©´?**
                - **(ì˜ˆì‹œ: HR ë¶„ì„)** ì „ì²´ ì§ì› ì¤‘ 'ì´ì§ì'ì™€ 'ì”ë¥˜ì'ë¥¼ ëª¨ë‘ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€ê°€ ì¤‘ìš”í•  ë•Œ ì„ íƒí•©ë‹ˆë‹¤.
                - **(ì£¼ì˜)** ë§Œì•½ ì”ë¥˜ìê°€ 95%ê³  ì´ì§ìê°€ 5%ë¼ë©´, ëª¨ë¸ì´ ì „ë¶€ 'ì”ë¥˜'ë¡œ ì˜ˆì¸¡í•´ë„ ì •í™•ë„ëŠ” 95%ê°€ ë‚˜ì˜µë‹ˆë‹¤. ë°ì´í„°ê°€ ë¶ˆê· í˜•í•  ë• ì‹ ë¢°í•˜ê¸° ì–´ë ¤ìš´ ì§€í‘œì…ë‹ˆë‹¤.

            - **Recall (ì¬í˜„ìœ¨)ì´ ì¤‘ìš”í•˜ë‹¤ë©´?**
                - **(ì˜ˆì‹œ: HR ë¶„ì„)** ì‹¤ì œ ì´ì§í•  ì§ì›(Positive)ì„ ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì•„ë‚´ëŠ” ê²ƒì´ ëª©í‘œì¼ ë•Œ ì„ íƒí•©ë‹ˆë‹¤. (ì˜ˆ: í•µì‹¬ ì¸ì¬ ìœ ì¶œ ë°©ì§€)
                - **False Negative (FN) ë¹„ìš©**ì´ ë§¤ìš° í´ ë•Œ (ì˜ˆ: ì´ì§í•  í•µì‹¬ ì¸ì¬ë¥¼ 'ì”ë¥˜'ë¡œ ì˜ëª» ì˜ˆì¸¡í•˜ì—¬ ì•„ë¬´ ì¡°ì¹˜ë„ ëª» í•˜ê³  ë†“ì¹¨) ì´ ì§€í‘œë¥¼ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.

            - **Precision (ì •ë°€ë„)ì´ ì¤‘ìš”í•˜ë‹¤ë©´?**
                - **(ì˜ˆì‹œ: HR ë¶„ì„)** ëª¨ë¸ì´ **'ì´ì§ì(Positive)'ë¼ê³  ì˜ˆì¸¡í•œ ì‚¬ëŒ**ì´ ì‹¤ì œë¡œ ì´ì§í•  í™•ë¥ ì´ ë†’ì•„ì•¼ í•  ë•Œ ì„ íƒí•©ë‹ˆë‹¤.
                - **False Positive (FP) ë¹„ìš©**ì´ ë§¤ìš° í´ ë•Œ (ì˜ˆ: ì”ë¥˜í•  ì§ì›ì„ 'ì´ì§ì'ë¡œ ì˜ëª» ì˜ˆì¸¡í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë©´ë‹´, ë³´ë„ˆìŠ¤ ì§€ê¸‰ ë“± ë¦¬ì†ŒìŠ¤ë¥¼ ë‚­ë¹„í•¨) ì´ ì§€í‘œë¥¼ ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.

            - **ROC-AUCê°€ ì¤‘ìš”í•˜ë‹¤ë©´?**
                - ëª¨ë¸ì´ 'ì´ì§ì'ì™€ 'ì”ë¥˜ì'ë¥¼ ì–¼ë§ˆë‚˜ ì˜ **êµ¬ë³„**í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ì „ë°˜ì ì¸ ì„±ëŠ¥ ì§€í‘œì…ë‹ˆë‹¤.
                - Recallê³¼ Precisionì´ ìƒì¶©(Trade-off) ê´€ê³„ì¼ ë•Œ, ëª¨ë¸ì˜ ì¢…í•©ì ì¸ ë¶„ë¥˜ ì„±ëŠ¥ì„ íŒë‹¨í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.
            
            - **F1-Scoreê°€ ì¤‘ìš”í•˜ë‹¤ë©´?**
                - Precisionê³¼ Recallì˜ **ì¡°í™” í‰ê· **ì…ë‹ˆë‹¤. ë‘ ì§€í‘œê°€ ëª¨ë‘ ì¤‘ìš”í•˜ì§€ë§Œ ë°ì´í„°ê°€ ë¶ˆê· í˜•í•  ë•Œ (ì˜ˆ: ì´ì§ìê°€ 5%ì¸ ê²½ìš°) Accuracyë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """
        )
        st.balloons()


# 4. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

if __name__ == "__main__":
    main()

# 4. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

if __name__ == "__main__":
    main()
